{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a TF model as an AKS web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this variable to your container registry\n",
    "# use the registry automatically created with the workspace as it is pre-authenticated with the workspace\n",
    "registry_address = \"abcxyz.azurecr.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core.workspace import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print(f\"Workspace: {ws.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get your model\n",
    "Your model may be stored in a repo, cloud storage, etc.\n",
    "The purpose of this cell is just to retrive your model so we can register it with AzureML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a sample resnet50 model from tensorflow.org as an example\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "from io import BytesIO\n",
    "\n",
    "model_url = \"http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NCHW_jpg.tar.gz\"\n",
    "archive_prefix = \"./resnet_v1_fp32_savedmodel_NCHW_jpg/1538686758/\"\n",
    "target_folder = \"resnet50_model\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    response = requests.get(model_url)\n",
    "    archive = tarfile.open(fileobj=BytesIO(response.content))\n",
    "    with tempfile.TemporaryDirectory() as temp_folder:\n",
    "        archive.extractall(temp_folder)\n",
    "        shutil.copytree(os.path.join(temp_folder, archive_prefix), target_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path=\"resnet50_model\", # This points to the local directory to upload.\n",
    "                       model_name=\"resnet50_model\", # This is the name the model is registered as.\n",
    "                       tags={'area': \"Image classification\", 'type': \"classification\"},\n",
    "                       description=\"Image classification trained on Imagenet Dataset\",\n",
    "                       workspace=ws)\n",
    "\n",
    "print(f\"model: {model.name}, description: {model.description}, version: {model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get target AKS Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "gpu_cluster_name = \"nc6-ic\"\n",
    "gpu_cluster = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "print(f\"AKS cluster: {gpu_cluster_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick one of the four options below to define an InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# OPTION 0: use built in DEFAULT_GPU_IMAGE + apply a conda config\n",
    "#\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment, DEFAULT_GPU_IMAGE # See https://github.com/Azure/AzureML-Containers/tree/master/base for default images definitions\n",
    "\n",
    "# Defining CondaDependencies\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "conda_dependencies = CondaDependencies.create(conda_packages=['tensorflow-gpu==1.12.0','numpy'],\n",
    "                                              pip_packages=['azureml-contrib-services', 'azureml-defaults'])\n",
    "\n",
    "# Defininig Environment\n",
    "env = Environment('tf-1.12.0-gpu')\n",
    "env.docker.base_image = DEFAULT_GPU_IMAGE\n",
    "env.python.conda_dependencies = conda_dependencies\n",
    "\n",
    "# InferenceConfig\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "aks_service_name ='resnet50-option0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# OPTION 1a: use a custom base image + apply a CondaDependencies objet\n",
    "#\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "# Defining CondaDependencies\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "conda_dependencies = CondaDependencies.create(conda_packages=['tensorflow-gpu==1.12.0','numpy'],\n",
    "                                              pip_packages=['azureml-contrib-services', 'azureml-defaults'])\n",
    "\n",
    "# Defining Environment\n",
    "env = Environment('tf-1.12.0-gpu')\n",
    "env.python.conda_dependencies = conda_dependencies\n",
    "env.docker.base_image = registry_address+\"/tf-1.12.0-gpu:option1\"\n",
    "env.inferencing_stack_version=\"latest\"\n",
    "\n",
    "# InferenceConfig\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "aks_service_name ='resnet50-option1a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# OPTION 1b: use a custom base image + apply a conda.yaml environment file definition\n",
    "#\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "# Defining Environment from a conda.yaml environment file\n",
    "env = Environment.from_conda_specification(name=\"tf-1.12.0-gpu\", file_path=\"option1-conda.yaml\")\n",
    "env.docker.base_image = registry_address+\"/tf-1.12.0-gpu:option1\"\n",
    "env.inferencing_stack_version=\"latest\"\n",
    "\n",
    "# InferenceConfig\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "aks_service_name ='resnet50-option1b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# OPTION 2: use a fully configured docker image\n",
    "#\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "env = Environment('tf-1.12.0-gpu')\n",
    "env.python.user_managed_dependencies=True\n",
    "env.docker.base_image = registry_address+\"/tf-1.12.0-gpu:option2\"\n",
    "env.inferencing_stack_version=\"latest\"\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "aks_service_name ='resnet50-option2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model as an AKS Service using the InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "aks_service = Model.deploy(workspace=ws,\n",
    "                           name=aks_service_name,\n",
    "                           models=[model],\n",
    "                           inference_config=inference_config,\n",
    "                           deployment_config=aks_config,\n",
    "                           deployment_target=gpu_cluster,\n",
    "                           overwrite=True)\n",
    "\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of error, you can display the service creation and boot logs\n",
    "print(aks_service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the web service\n",
    "We test the web sevice by passing the test images content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import requests\n",
    "\n",
    "# if (key) auth is enabled, fetch keys and include in the request\n",
    "key1, key2 = aks_service.get_keys()\n",
    "\n",
    "headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + key1}\n",
    "\n",
    "# # if token auth is enabled, fetch token and include in the request\n",
    "# access_token, fetch_after = aks_service.get_token()\n",
    "# headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + access_token}\n",
    "\n",
    "test_sample = open('test_image.jpg', 'rb').read()\n",
    "resp = requests.post(aks_service.scoring_uri, test_sample, headers=headers)\n",
    "print(resp)\n",
    "print(resp.text)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "vaidyas"
   }
  ],
  "categories": [
   "how-to-use-azureml",
   "deployment"
  ],
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}